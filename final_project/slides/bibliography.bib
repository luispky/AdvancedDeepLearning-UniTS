@misc{cohen_group_2016,
  title      = {Group Equivariant Convolutional Networks},
  url        = {http://arxiv.org/abs/1602.07576},
  doi        = {10.48550/arXiv.1602.07576},
  abstract   = {We introduce Group equivariant Convolutional Neural Networks (G-{CNNs}), a natural generalization of convolutional neural networks that reduces sample complexity by exploiting symmetries. G-{CNNs} use G-convolutions, a new type of layer that enjoys a substantially higher degree of weight sharing than regular convolution layers. G-convolutions increase the expressive capacity of the network without increasing the number of parameters. Group convolution layers are easy to use and can be implemented with negligible computational overhead for discrete groups generated by translations, reflections and rotations. G-{CNNs} achieve state of the art results on {CIFAR}10 and rotated {MNIST}.},
  number     = {{arXiv}:1602.07576},
  publisher  = {{arXiv}},
  author     = {Cohen, Taco S. and Welling, Max},
  urldate    = {2025-07-06},
  date       = {2016-06-03},
  eprinttype = {arxiv},
  eprint     = {1602.07576 [cs]},
  keywords   = {Computer Science - Machine Learning, Statistics - Machine Learning},
  file       = {Preprint PDF:/home/l11/Zotero/storage/8FUB3WGL/Cohen and Welling - 2016 - Group Equivariant Convolutional Networks.pdf:application/pdf}
}


@article{thill_group_2015,
  title        = {Group Frames with Few Distinct Inner Products and Low Coherence},
  volume       = {63},
  issn         = {1053-587X, 1941-0476},
  url          = {http://arxiv.org/abs/1509.05087},
  doi          = {10.1109/TSP.2015.2450195},
  abstract     = {Frame theory has been a popular subject in the design of structured signals and codes in recent years, with applications ranging from the design of measurement matrices in compressive sensing, to spherical codes for data compression and data transmission, to spacetime codes for {MIMO} communications, and to measurement operators in quantum sensing. High-performance codes usually arise from designing frames whose elements have mutually low coherence. Building off the original "group frame" design of Slepian which has since been elaborated in the works of Vale and Waldron, we present several new frame constructions based on cyclic and generalized dihedral groups. Slepian's original construction was based on the premise that group structure allows one to reduce the number of distinct inner pairwise inner products in a frame with \$n\$ elements from \${\textbackslash}frac\{n(n-1)\}\{2\}\$ to \$n-1\$. All of our constructions further utilize the group structure to produce tight frames with even fewer distinct inner product values between the frame elements. When \$n\$ is prime, for example, we use cyclic groups to construct \$m\$-dimensional frame vectors with at most \${\textbackslash}frac\{n-1\}\{m\}\$ distinct inner products. We use this behavior to bound the coherence of our frames via arguments based on the frame potential, and derive even tighter bounds from combinatorial and algebraic arguments using the group structure alone. In certain cases, we recover well-known Welch bound achieving frames. In cases where the Welch bound has not been achieved, and is not known to be achievable, we obtain frames with close to Welch bound performance.},
  pages        = {5222--5237},
  number       = {19},
  journaltitle = {{IEEE} Transactions on Signal Processing},
  shortjournal = {{IEEE} Trans. Signal Process.},
  author       = {Thill, Matthew and Hassibi, Babak},
  urldate      = {2025-07-06},
  date         = {2015-10},
  eprinttype   = {arxiv},
  eprint       = {1509.05087 [cs]},
  keywords     = {Computer Science - Information Theory, Mathematics - Information Theory},
  file         = {Full Text PDF:/home/l11/Zotero/storage/6WQ2Q8P9/Thill and Hassibi - 2015 - Group Frames with Few Distinct Inner Products and Low Coherence.pdf:application/pdf;Snapshot:/home/l11/Zotero/storage/LCJPKVG8/1509.html:text/html}
}

@misc{thill_low-coherence_2015,
  title      = {Low-Coherence Frames from Group Fourier Matrices},
  url        = {http://arxiv.org/abs/1509.05739},
  doi        = {10.48550/arXiv.1509.05739},
  abstract   = {Many problems in areas such as compressive sensing and coding theory seek to design a set of equal-norm vectors with large angular separation. This idea is essentially equivalent to constructing a frame with low coherence. The elements of such frames can in turn be used to build high-performance spherical codes, quantum measurement operators, and compressive sensing measurement matrices, to name a few applications. In this work, we allude to the group-frame construction first described by Slepian and further explored in the works of Vale and Waldron. We present a method for selecting representations of a finite group to construct a group frame that achieves low coherence. Our technique produces a tight frame with a small number of distinct inner product values between the frame elements, in a sense approximating a Grassmanian frame. We identify special cases in which our construction yields some previously-known frames with optimal coherence meeting the Welch lower bound, and other cases in which the entries of our frame vectors come from small alphabets. In particular, we apply our technique to the problem choosing a subset of rows of a Hadamard matrix so that the resulting columns form a low-coherence frame. Finally, we give an explicit calculation of the average coherence of our frames, and find regimes in which they satisfy the Strong Coherence Property described by Mixon, Bajwa, and Calderbank.},
  number     = {{arXiv}:1509.05739},
  publisher  = {{arXiv}},
  author     = {Thill, Matthew and Hassibi, Babak},
  urldate    = {2025-07-06},
  date       = {2015-09-18},
  eprinttype = {arxiv},
  eprint     = {1509.05739 [cs]},
  keywords   = {Computer Science - Information Theory, Mathematics - Information Theory},
  file       = {Preprint PDF:/home/l11/Zotero/storage/JLLZZY46/Thill and Hassibi - 2015 - Low-Coherence Frames from Group Fourier Matrices.pdf:application/pdf}
}

@online{bekkers_uvagedl,
  title    = {{UvA} - An Introduction to Group Equivariant Deep Learning},
  url      = {https://uvagedl.github.io/},
  abstract = {Materials for the group equivariant deep learning course},
  author   = {Erik Bekkers},
  langid   = {american},
  file     = {Snapshot:/home/l11/Zotero/storage/UMB44JSK/uvagedl.github.io.html:text/html},
  year     = {2025},
  urldate  = {}
}

@article{veefkind_probabilistic_2024,
  title   = {A Probabilistic Approach to Learning the Degree of Equivariance in Steerable {CNNs}},
  author  = {Veefkind, Lars},
  langid  = {english},
  file    = {PDF:/home/l11/Zotero/storage/BG53C8F6/Veefkind - A Probabilistic Approach to Learning the Degree of Equivariance in Steerable CNNs.pdf:application/pdf},
  year    = {2024},
  urldate = {}
}

@article{bekkers_introduction_2021,
  title   = {An Introduction to Equivariant Convolutional  Neural Networks for Continuous Groups},
  author  = {Bekkers, Erik J.},
  langid  = {english},
  url     = {https://uvagedl.github.io/GroupConvLectureNotes.pdf},
  year    = {2021},
  urldate = {}
}

@online{wikipedia_logsumexp_2024,
  title        = {{LogSumExp}},
  url          = {https://en.wikipedia.org/wiki/LogSumExp},
  abstract     = {The LogSumExp (LSE) (also called RealSoftMax or multivariable softplus) function is a smooth maximum â€“ a smooth approximation to the maximum function, mainly used by machine learning algorithms.},
  author       = {{Wikipedia contributors}},
  organization = {Wikipedia, The Free Encyclopedia},
  urldate      = {2025-01-27},
  date         = {2024-06-23},
  langid       = {english}
}


@online{knigge_gdl_2024,
	title = {Regular Group Convolutions},
	url = {https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/DL2/Geometric_deep_learning/tutorial1_regular_group_convolutions.html},
	abstract = {Tutorial on regular group convolutions as part of the geometric deep learning series, covering the mathematical foundations and practical implementation of group equivariant neural networks.},
	author = {Knigge, David and Lippe, Phillip},
	organization = {University of Amsterdam Deep Learning Tutorials},
	urldate = {2025-01-27},
	year = {2024},
	langid = {english},
}
